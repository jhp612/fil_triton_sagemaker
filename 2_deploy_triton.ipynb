{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5bfbad",
   "metadata": {},
   "source": [
    "# Triton on SageMaker - Ensemble + FIL Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3eddc",
   "metadata": {},
   "source": [
    "## Set up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e3175",
   "metadata": {},
   "source": [
    "Installs the dependencies required to package the model and run inferences using Triton server.\n",
    "\n",
    "Also define the IAM role that will give SageMaker access to the model artifacts and the NVIDIA Triton ECR image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f185ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pip awscli boto3 sagemaker \n",
    "!pip install nvidia-pyindex\n",
    "!pip install tritonclient[http]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5841a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "import time\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "role = get_execution_role()\n",
    "client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "926e0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    'us-east-1': '785573368785',\n",
    "    'us-east-2': '007439368137',\n",
    "    'us-west-1': '710691900526',\n",
    "    'us-west-2': '301217895009',\n",
    "    'eu-west-1': '802834080501',\n",
    "    'eu-west-2': '205493899709',\n",
    "    'eu-west-3': '254080097072',\n",
    "    'eu-north-1': '601324751636',\n",
    "    'eu-south-1': '966458181534',\n",
    "    'eu-central-1': '746233611703',\n",
    "    'ap-east-1': '110948597952',\n",
    "    'ap-south-1': '763008648453',\n",
    "    'ap-northeast-1': '941853720454',\n",
    "    'ap-northeast-2': '151534178276',\n",
    "    'ap-southeast-1': '324986816169',\n",
    "    'ap-southeast-2': '355873309152',\n",
    "    'cn-northwest-1': '474822919863',\n",
    "    'cn-north-1': '472730292857',\n",
    "    'sa-east-1': '756306329178',\n",
    "    'ca-central-1': '464438896020',\n",
    "    'me-south-1': '836785723513',\n",
    "    'af-south-1': '774647643957'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb860eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise(\"UNSUPPORTED REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ffa8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.05-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#triton_image_uri = \"354625738399.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tritonserver:22.05-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "494804f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tritonserver:22.05-py3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36ec3b",
   "metadata": {},
   "source": [
    "## Package models and dependencies and uploading to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1edb841",
   "metadata": {},
   "source": [
    "First we create the Triton config file for the XGBoost model being served by the FIL Backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea46a715",
   "metadata": {},
   "source": [
    "**TODO**: Note the reshape we had to do for output here. This is specific to this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4a6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "MODEL_DIR = './triton-serve/fil'\n",
    "\n",
    "# Maximum size in bytes for input and output arrays\n",
    "MAX_MEMORY_BYTES = 60_000_000\n",
    "NUM_FEATURES = 15\n",
    "NUM_CLASSES = 2\n",
    "bytes_per_sample = (NUM_FEATURES + NUM_CLASSES) * 4\n",
    "max_batch_size = MAX_MEMORY_BYTES // bytes_per_sample\n",
    "\n",
    "IS_CLASSIFIER = True\n",
    "model_format = 'xgboost_json'\n",
    "\n",
    "# Select deployment hardware (GPU or CPU)\n",
    "if USE_GPU:\n",
    "    instance_kind = 'KIND_GPU'\n",
    "else:\n",
    "    instance_kind = 'KIND_CPU'\n",
    "\n",
    "# whether the model is doing classification or regression    \n",
    "if IS_CLASSIFIER:\n",
    "    classifier_string = 'true'\n",
    "else:\n",
    "    classifier_string = 'false'\n",
    "\n",
    "# whether to predict probabilites or not\n",
    "predict_proba = False\n",
    "\n",
    "if predict_proba:\n",
    "    predict_proba_string = 'true'\n",
    "else:\n",
    "    predict_proba_string = 'false'\n",
    "\n",
    "config_text = f\"\"\"backend: \"fil\"\n",
    "max_batch_size: {max_batch_size}\n",
    "input [                                 \n",
    " {{  \n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ {NUM_FEATURES} ]                    \n",
    "  }} \n",
    "]\n",
    "output [\n",
    " {{\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "    reshape: {{ shape: [ 1 ] }}\n",
    "  }}\n",
    "]\n",
    "instance_group [{{ kind: {instance_kind} }}]\n",
    "parameters [\n",
    "  {{\n",
    "    key: \"model_type\"\n",
    "    value: {{ string_value: \"{model_format}\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"predict_proba\"\n",
    "    value: {{ string_value: \"{predict_proba_string}\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"output_class\"\n",
    "    value: {{ string_value: \"{classifier_string}\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"threshold\"\n",
    "    value: {{ string_value: \"0.5\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"storage_type\"\n",
    "    value: {{ string_value: \"AUTO\" }}\n",
    "  }}\n",
    "]\n",
    "\n",
    "dynamic_batching {{}}\"\"\"\n",
    "\n",
    "config_path = os.path.join(MODEL_DIR, 'config.pbtxt')\n",
    "with open(config_path, 'w') as file_:\n",
    "    file_.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b25db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the RAPIDS 22.04 Conda env to be used in Python preprocessing\n",
    "!wget -q -P model_repository/preprocessing https://rapidsai-data.s3.us-east-2.amazonaws.com/conda-pack/rapidsai/rapids22.06_cuda11.5_py3.8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1363686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv model_repository/preprocessing/rapids22.06_cuda11.5_py3.8.tar.gz ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move label encoders into python preprocessing directory\n",
    "!cp label_encoders.pkl triton-serve/preprocessing/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df44939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move trained xgboost model into fil model directory\n",
    "!mkdir -p triton-serve/fil/1\n",
    "!cp xgboost.json triton-serve/fil/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a4d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model version directory for ensemble model\n",
    "!mkdir -p triton-serve/ensemble_preprocess_fil_postprocess/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d877aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cvzf model.tar.gz -C model_repository ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = sagemaker_session.upload_data(path=\"model.tar.gz\", key_prefix=\"triton-serve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f79530",
   "metadata": {},
   "source": [
    "## Create SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f781e04",
   "metadata": {},
   "source": [
    "We start off by creating a sagemaker model from the model files we uploaded to s3 in the previous step.\n",
    "\n",
    "In this step we also provide an additional Environment Variable i.e. SAGEMAKER_TRITON_DEFAULT_MODEL_NAME which specifies the name of the model to be loaded by Triton. The value of this key should match the folder name in the model package uploaded to s3. This variable is optional in case of a single model. In case of ensemble models, this key has to be specified for Triton to startup in SageMaker.\n",
    "\n",
    "Additionally, customers can set SAGEMAKER_TRITON_BUFFER_MANAGER_THREAD_COUNT and SAGEMAKER_TRITON_THREAD_COUNT for optimizing the thread counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601a207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5980d63",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e313e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4978f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_infer = pd.read_csv(\"data_infer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e670409a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": list(sample_data.shape), \"datatype\": \"STRING\", \"data\": sample_data},\n",
    "    ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
