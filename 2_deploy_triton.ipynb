{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d88325d",
   "metadata": {},
   "source": [
    "# Triton on SageMaker - Ensemble + FIL Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239ef17",
   "metadata": {},
   "source": [
    "## Set up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859fc8a",
   "metadata": {},
   "source": [
    "Installs the dependencies required to package the model and run inferences using Triton server.\n",
    "\n",
    "Also define the IAM role that will give SageMaker access to the model artifacts and the NVIDIA Triton ECR image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0dd92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 30 19:18:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   29C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8b3b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.20 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting nvidia-pyindex\n",
      "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-pyindex\n",
      "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8413 sha256=e6b703223c09e7427d1dc19dd14901b8b7a19069dca40c1dc771998c18a0ca86\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e0/c2/fb/5cf4e1cfaf28007238362cb746fb38fc2dd76348331a748d54\n",
      "Successfully built nvidia-pyindex\n",
      "Installing collected packages: nvidia-pyindex\n",
      "Successfully installed nvidia-pyindex-1.0.9\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting tritonclient[http]\n",
      "  Downloading tritonclient-2.23.0-py3-none-manylinux1_x86_64.whl (8.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-rapidjson>=0.9.1\n",
      "  Downloading python_rapidjson-1.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m397.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tritonclient[http]) (1.20.3)\n",
      "Collecting geventhttpclient>=1.4.4\n",
      "  Downloading geventhttpclient-1.5.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m293.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (2021.10.8)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m371.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gevent>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (21.8.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (1.16.0)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (59.4.0)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (5.4.0)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (1.1.2)\n",
      "Installing collected packages: brotli, python-rapidjson, tritonclient, geventhttpclient\n",
      "Successfully installed brotli-1.0.9 geventhttpclient-1.5.5 python-rapidjson-1.6 tritonclient-2.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU pip awscli boto3 sagemaker \n",
    "!pip install nvidia-pyindex\n",
    "!pip install tritonclient[http]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aec4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "import time\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "role = get_execution_role()\n",
    "client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982b5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    'us-east-1': '785573368785',\n",
    "    'us-east-2': '007439368137',\n",
    "    'us-west-1': '710691900526',\n",
    "    'us-west-2': '301217895009',\n",
    "    'eu-west-1': '802834080501',\n",
    "    'eu-west-2': '205493899709',\n",
    "    'eu-west-3': '254080097072',\n",
    "    'eu-north-1': '601324751636',\n",
    "    'eu-south-1': '966458181534',\n",
    "    'eu-central-1': '746233611703',\n",
    "    'ap-east-1': '110948597952',\n",
    "    'ap-south-1': '763008648453',\n",
    "    'ap-northeast-1': '941853720454',\n",
    "    'ap-northeast-2': '151534178276',\n",
    "    'ap-southeast-1': '324986816169',\n",
    "    'ap-southeast-2': '355873309152',\n",
    "    'cn-northwest-1': '474822919863',\n",
    "    'cn-north-1': '472730292857',\n",
    "    'sa-east-1': '756306329178',\n",
    "    'ca-central-1': '464438896020',\n",
    "    'me-south-1': '836785723513',\n",
    "    'af-south-1': '774647643957'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e492d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise(\"UNSUPPORTED REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afcccd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.05-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6fa580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#triton_image_uri = \"354625738399.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tritonserver:22.05-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab7fe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tritonserver:22.05-py3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91b3ef",
   "metadata": {},
   "source": [
    "## Package models and dependencies and uploading to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722f7a4",
   "metadata": {},
   "source": [
    "First we create the Triton config file for the XGBoost model being served by the FIL Backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04c300",
   "metadata": {},
   "source": [
    "**TODO**: Note the reshape we had to do for output here. This is specific to this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a6a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "FIL_MODEL_DIR = './model_repository/fil'\n",
    "\n",
    "# Maximum size in bytes for input and output arrays\n",
    "MAX_MEMORY_BYTES = 60_000_000\n",
    "NUM_FEATURES = 15\n",
    "NUM_CLASSES = 2\n",
    "bytes_per_sample = (NUM_FEATURES + NUM_CLASSES) * 4\n",
    "max_batch_size = MAX_MEMORY_BYTES // bytes_per_sample\n",
    "\n",
    "IS_CLASSIFIER = True\n",
    "model_format = 'xgboost_json'\n",
    "\n",
    "# Select deployment hardware (GPU or CPU)\n",
    "if USE_GPU:\n",
    "    instance_kind = 'KIND_GPU'\n",
    "else:\n",
    "    instance_kind = 'KIND_CPU'\n",
    "\n",
    "# whether the model is doing classification or regression    \n",
    "if IS_CLASSIFIER:\n",
    "    classifier_string = 'true'\n",
    "else:\n",
    "    classifier_string = 'false'\n",
    "\n",
    "# whether to predict probabilites or not\n",
    "predict_proba = False\n",
    "\n",
    "if predict_proba:\n",
    "    predict_proba_string = 'true'\n",
    "else:\n",
    "    predict_proba_string = 'false'\n",
    "\n",
    "config_text = f\"\"\"backend: \"fil\"\n",
    "max_batch_size: {max_batch_size}\n",
    "input [                                 \n",
    " {{  \n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ {NUM_FEATURES} ]                    \n",
    "  }} \n",
    "]\n",
    "output [\n",
    " {{\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }}\n",
    "]\n",
    "instance_group [{{ kind: {instance_kind} }}]\n",
    "parameters [\n",
    "  {{\n",
    "    key: \"model_type\"\n",
    "    value: {{ string_value: \"{model_format}\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"predict_proba\"\n",
    "    value: {{ string_value: \"{predict_proba_string}\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"output_class\"\n",
    "    value: {{ string_value: \"{classifier_string}\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"threshold\"\n",
    "    value: {{ string_value: \"0.5\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"storage_type\"\n",
    "    value: {{ string_value: \"AUTO\" }}\n",
    "  }}\n",
    "]\n",
    "\n",
    "dynamic_batching {{}}\"\"\"\n",
    "\n",
    "config_path = os.path.join(FIL_MODEL_DIR, 'config.pbtxt')\n",
    "with open(config_path, 'w') as file_:\n",
    "    file_.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the RAPIDS 22.04 Conda env to be used in Python preprocessing\n",
    "!wget -q -P model_repository/preprocessing https://rapidsai-data.s3.us-east-2.amazonaws.com/conda-pack/rapidsai/rapids22.06_cuda11.5_py3.8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move label encoders into python preprocessing directory\n",
    "!cp label_encoders.pkl model_repository/preprocessing/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8a545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move trained xgboost model into fil model directory\n",
    "!mkdir -p model_repository/fil/1\n",
    "!cp xgboost.json model_repository/fil/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6e5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model version directory for ensemble model\n",
    "!mkdir -p model_repository/ensemble/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13a3e069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./ensemble/\n",
      "./ensemble/1/\n",
      "./ensemble/config.pbtxt\n",
      "./fil/\n",
      "./fil/1/\n",
      "./fil/1/xgboost.json\n",
      "./fil/config.pbtxt\n",
      "./preprocessing/\n",
      "./preprocessing/1/\n",
      "./preprocessing/1/model.py\n",
      "./preprocessing/1/__pycache__/\n",
      "./preprocessing/1/__pycache__/model.cpython-38.pyc\n",
      "./preprocessing/1/label_encoders.pkl\n",
      "./preprocessing/config.pbtxt\n",
      "./preprocessing/rapids22.06_cuda11.5_py3.8.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!tar --exclude='.ipynb_checkpoints' -czvf model.tar.gz -C model_repository ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd577382",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = sagemaker_session.upload_data(path=\"model.tar.gz\", key_prefix=\"triton-fil-ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da22f31",
   "metadata": {},
   "source": [
    "## Create SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845105a6",
   "metadata": {},
   "source": [
    "We start off by creating a sagemaker model from the model files we uploaded to s3 in the previous step.\n",
    "\n",
    "In this step we also provide an additional Environment Variable i.e. `SAGEMAKER_TRITON_DEFAULT_MODEL_NAME` which specifies the name of the model to be loaded by Triton. **The value of this key should match the folder name in the model package uploaded to s3.** This variable is optional in case of a single model. In case of ensemble models, this **key has to be specified** for Triton to startup in SageMaker.\n",
    "\n",
    "Additionally, customers can set `SAGEMAKER_TRITON_BUFFER_MANAGER_THREAD_COUNT` and `SAGEMAKER_TRITON_THREAD_COUNT` for optimizing the thread counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d7ffb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Arn: arn:aws:sagemaker:us-west-2:354625738399:model/triton-fil-ensemble-2022-06-30-04-36-30\n"
     ]
    }
   ],
   "source": [
    "sm_model_name = \"triton-fil-ensemble-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "container = {\n",
    "    \"Image\": triton_image_uri,\n",
    "    \"ModelDataUrl\": model_uri,\n",
    "    \"Environment\": {\"SAGEMAKER_TRITON_DEFAULT_MODEL_NAME\": \"ensemble\"},\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c98a4",
   "metadata": {},
   "source": [
    "Using the model above, we create an endpoint configuration where we can specify the type and number of instances we want in the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eadd3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Config Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint-config/triton-fil-ensemble-2022-06-30-04-36-31\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = \"triton-fil-ensemble-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g4dn.4xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e6f24",
   "metadata": {},
   "source": [
    "Using the above endpoint configuration we create a new sagemaker endpoint and wait for the deployment to finish. The status will change to InService once the deployment is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa048a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint/triton-fil-ensemble-2022-06-30-04-36-31\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"triton-fil-ensemble-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f210e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-west-2:354625738399:endpoint/triton-fil-ensemble-2022-06-30-04-36-31\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0c55a",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b160d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583892ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_infer = pd.read_csv(\"data_infer.csv\").iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e603323",
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_COL_NAMES = ['Time', 'Amount', 'Zip', 'MCC', 'Merchant Name', 'Use Chip', 'Merchant City', 'Merchant State', 'Errors?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc915dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "payload[\"inputs\"] = []\n",
    "data_dict = {}\n",
    "for col in data_infer.columns:\n",
    "    data_dict[col] = {}\n",
    "    if col in STR_COL_NAMES:\n",
    "        data_dict[col]['data'] = np.expand_dims(data_infer[col].astype(str).values, axis=-1).tolist()\n",
    "        data_dict[col]['datatype'] = 'STRING'\n",
    "    else:\n",
    "        data_dict[col]['data'] = np.expand_dims(data_infer[col].astype(np.float32).values, axis=-1).tolist()\n",
    "        data_dict[col]['datatype'] = 'FP32'\n",
    "    data_dict[col]['shape'] = [len(data_infer), 1]\n",
    "    payload[\"inputs\"].append(data_dict[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bbed153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': [{'data': [[1005.0], [134.0]], 'datatype': 'FP32', 'shape': [2, 1]},\n",
       "  {'data': [[0.0], [5.0]], 'datatype': 'FP32', 'shape': [2, 1]},\n",
       "  {'data': [[2013.0], [2015.0]], 'datatype': 'FP32', 'shape': [2, 1]},\n",
       "  {'data': [[6.0], [2.0]], 'datatype': 'FP32', 'shape': [2, 1]},\n",
       "  {'data': [[5.0], [16.0]], 'datatype': 'FP32', 'shape': [2, 1]},\n",
       "  {'data': [['22:03'], ['18:34']], 'datatype': 'STRING', 'shape': [2, 1]},\n",
       "  {'data': [['$-180.00'], ['$99.10']], 'datatype': 'STRING', 'shape': [2, 1]},\n",
       "  {'data': [['Swipe Transaction'], ['Chip Transaction']],\n",
       "   'datatype': 'STRING',\n",
       "   'shape': [2, 1]},\n",
       "  {'data': [['7834055923142137930'], ['-1548923525906069124']],\n",
       "   'datatype': 'STRING',\n",
       "   'shape': [2, 1]},\n",
       "  {'data': [['Orlando'], ['Tyler']], 'datatype': 'STRING', 'shape': [2, 1]},\n",
       "  {'data': [['FL'], ['TX']], 'datatype': 'STRING', 'shape': [2, 1]},\n",
       "  {'data': [['32808.0'], ['75706.0']], 'datatype': 'STRING', 'shape': [2, 1]},\n",
       "  {'data': [['3395'], ['4900']], 'datatype': 'STRING', 'shape': [2, 1]},\n",
       "  {'data': [['nan'], ['nan']], 'datatype': 'STRING', 'shape': [2, 1]}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e880c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'triton-fil-ensemble-2022-06-30-04-36-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99b4190c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"Unable to parse 'name': attempt to access non-existing object member 'name'\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/triton-fil-ensemble-2022-06-30-04-36-31 in account 354625738399 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18792/825665316.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = client.invoke_endpoint(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"application/octet-stream\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 )\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"Unable to parse 'name': attempt to access non-existing object member 'name'\"}\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/triton-fil-ensemble-2022-06-30-04-36-31 in account 354625738399 for more information."
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"application/octet-stream\", Body=json.dumps(payload)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(response[\"Body\"].read().decode(\"utf8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a11fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
