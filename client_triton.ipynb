{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00d1239-ec89-48fd-94e4-db6aa4fe8f81",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tritonclient[http] in /usr/local/lib/python3.8/dist-packages (2.22.4)\n",
      "Requirement already satisfied: python-rapidjson>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from tritonclient[http]) (1.6)\n",
      "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.8/dist-packages (from tritonclient[http]) (1.22.4)\n",
      "Requirement already satisfied: geventhttpclient>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from tritonclient[http]) (1.5.4)\n",
      "Requirement already satisfied: brotli in /usr/local/lib/python3.8/dist-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (1.0.9)\n",
      "Requirement already satisfied: gevent>=0.13 in /usr/local/lib/python3.8/dist-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (21.12.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (1.14.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (2019.11.28)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (1.1.2)\n",
      "Requirement already satisfied: zope.interface in /usr/local/lib/python3.8/dist-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (5.4.0)\n",
      "Requirement already satisfied: zope.event in /usr/local/lib/python3.8/dist-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (62.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q tritonclient[http]\n",
    "!pip install -q pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c442af8-698c-45e9-8e15-53fea4454b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton_python_backend_utils as pb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e16ccc6-d71d-4fd5-b1bd-16e0ac77981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import np_to_triton_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43d060f7-34cf-40c3-9348-d48da0b31e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f42b3bfb-f601-447b-885c-1a49ac623704",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = httpclient.InferenceServerClient(url='localhost:8000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db69e573-1150-4943-a16d-5044abb32079",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_infer = pd.read_csv(\"data_infer.csv\").astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ace55631-b024-42df-944c-89e9c386faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data_infer.iloc[:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a600bfb0-7385-4d4f-a945-592e3a807517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tensor(name, input_data):\n",
    "    tensor = httpclient.InferInput(\n",
    "        name, input_data.shape, np_to_triton_dtype(input_data.dtype))\n",
    "    tensor.set_data_from_numpy(input_data)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9778f83-3a0c-4a7f-86b0-3069c0ee8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"preprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5f7f8ff-9d24-4ad2-b8cb-11c14d0554a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [prepare_tensor('INPUT', input_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "220ea11f-d2ae-4215-b670-f96d3b00ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f2e60b1f-f733-4f83-bca7-f3ca774fa9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceServerException",
     "evalue": "Failed to process the request(s) for model instance 'preprocessing_0', message: Number of InferenceResponse objects do not match the number of InferenceRequest objects. InferenceRequest(s) size is:1, and InferenceResponse(s) size is:0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py:1418\u001b[0m, in \u001b[0;36mInferenceServerClient.infer\u001b[0;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, headers, query_params, request_compression_algorithm, response_compression_algorithm)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     request_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2/models/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/infer\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(quote(model_name))\n\u001b[1;32m   1414\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(request_uri\u001b[38;5;241m=\u001b[39mrequest_uri,\n\u001b[1;32m   1415\u001b[0m                       request_body\u001b[38;5;241m=\u001b[39mrequest_body,\n\u001b[1;32m   1416\u001b[0m                       headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1417\u001b[0m                       query_params\u001b[38;5;241m=\u001b[39mquery_params)\n\u001b[0;32m-> 1418\u001b[0m \u001b[43m_raise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m InferResult(response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py:65\u001b[0m, in \u001b[0;36m_raise_if_error\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     63\u001b[0m error \u001b[38;5;241m=\u001b[39m _get_error(response)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mInferenceServerException\u001b[0m: Failed to process the request(s) for model instance 'preprocessing_0', message: Number of InferenceResponse objects do not match the number of InferenceRequest objects. InferenceRequest(s) size is:1, and InferenceResponse(s) size is:0\n"
     ]
    }
   ],
   "source": [
    "response = client.infer(model_name,\n",
    "                        inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118ed72-c2a4-4024-a5ef-bb0da39c1e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ba8e8-2f6f-4a1c-b0ed-3a4ac1f52306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1ee57-5679-47d7-ae4d-b292d73b27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = response.as_numpy(\"AMOUNT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af397952-9414-4267-ad4f-f2b79adf1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45.23]\n"
     ]
    }
   ],
   "source": [
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73313f-6430-43e5-8a22-422376d3b570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
